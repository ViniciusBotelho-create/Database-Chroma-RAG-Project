{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17675098-2f9e-4e09-8e53-e4f1bcfc567b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stoiccode/gitRepositories/Database-Chroma-RAG-Project/venv311/lib64/python3.11/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import fitz\n",
    "import spacy\n",
    "import json\n",
    "import requests\n",
    "import openai\n",
    "import os\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pymongo import MongoClient\n",
    "from chromadb import Client as ChromaClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d570aa-e6fe-4563-8c0d-136b0e3f2044",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1442985295.py, line 5)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmongo_client = MongoClient(\"mongodb://localhost:27017\") mongo_db = mongo_client[\"rag_db\"] mongo_chunks = mongo_db[\"chunks\"]\u001b[39m\n                                                            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Configurando o ChromaDB com persistência\n",
    "chroma_client = chromadb.PersistentClient(path=\"../chroma_db\")\n",
    "\n",
    "#Conexões com o mongodb¶\n",
    "mongo_client = MongoClient(\"mongodb://localhost:27017\") mongo_db = mongo_client[\"rag_db\"] mongo_chunks = mongo_db[\"chunks\"]\n",
    "collection = chroma_client.get_or_create_collection(name=\"rag_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a119aff8-5a2b-437c-bccf-514b514c29c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando: https://cetesb.sp.gov.br/eiarima/eia/EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf...\n",
      "Processando: ./temp_pdfs/EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf...\n",
      "Baixando: https://cetesb.sp.gov.br/eiarima/rima/RIMA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf...\n",
      "Processando: ./temp_pdfs/RIMA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf...\n",
      "Baixando: https://www.ibama.gov.br/phocadownload/licenciamento/publicacoes/2020-11-TR_CEM.pdf...\n",
      "Processando: ./temp_pdfs/2020-11-TR_CEM.pdf...\n",
      "Baixando: https://www2.senado.leg.br/bdsf/bitstream/handle/id/645769/CF88_EC132_livro.pdf...\n",
      "Processando: ./temp_pdfs/CF88_EC132_livro.pdf...\n",
      "Baixando: https://conama.mma.gov.br/?option=com_sisconama&task=arquivo.download&id=237...\n",
      "Processando: ./temp_pdfs/?option=com_sisconama&task=arquivo.download&id=237...\n",
      "Baixando: https://www.ibama.gov.br/sophia/cnia/legislacao/IBAMA/IN0184-170708.PDF...\n",
      "Processando: ./temp_pdfs/IN0184-170708.PDF...\n",
      "Baixando: https://cetesb.sp.gov.br/eiarima/eia/EIA-096-24-e-amb-14575-24-Lot-Resid-Jequitiba-Boituva.pdf...\n",
      "Processando: ./temp_pdfs/EIA-096-24-e-amb-14575-24-Lot-Resid-Jequitiba-Boituva.pdf...\n",
      "Baixando: https://cetesb.sp.gov.br/eiarima/rima/RIMA-096-24-e-amb-14575-24-Lot-Resid-Jequitiba-Boituva.pdf...\n",
      "Processando: ./temp_pdfs/RIMA-096-24-e-amb-14575-24-Lot-Resid-Jequitiba-Boituva.pdf...\n",
      "Baixando: https://conama.mma.gov.br/?option=com_sisconama&task=arquivo.download&id=745...\n",
      "Processando: ./temp_pdfs/?option=com_sisconama&task=arquivo.download&id=745...\n",
      "Extração concluída para 9 documentos.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Diretório temporário para armazenar PDFs baixados\n",
    "download_dir = './temp_pdfs/'\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# Carrega o modelo e aumenta o limite máximo de caracteres\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "nlp.max_length = 2_000_000\n",
    "\n",
    "# Palavras e frases a ignorar\n",
    "GENERIC_IGNORE_KEYWORDS = {\n",
    "    \"sumário\", \"índice\", \"resumo\", \"anexo\", \"figura\", \"tabela\", \"referência\", \"bibliografia\",\n",
    "    \"conteúdo\", \"protocolo\", \"gov\", \"secretaria\", \"assinatura\", \"documento assinado\",\n",
    "    \"orientações gerais\", \"preenchimento\", \"manual\", \"parecer técnico\"\n",
    "}\n",
    "\n",
    "PHRASE_BLACKLIST = [\n",
    "    r\"monitoramento de.*\\(e-cenários\\)\",\n",
    "    r\"^página \\d+.*\",\n",
    "    r\"^mapas\\s*-\\s*\",\n",
    "    r\"^inserção do estudo.*\",\n",
    "    r\"^um arquivo não substitui.*\",\n",
    "    r\"^o link para.*tipologia.*\",\n",
    "    r\"documentos, manifestações.*\",\n",
    "    r\"requerimento.*preenchido.*\",\n",
    "    r\"documento.*válido.*\"\n",
    "]\n",
    "\n",
    "KEY_VERBS = {\n",
    "    \"avaliar\", \"caracterizar\", \"delimitar\", \"analisar\", \"estimar\",\n",
    "    \"descrever\", \"propor\", \"identificar\", \"considerar\", \"indicar\",\n",
    "    \"demonstrar\", \"impactar\", \"recomendar\", \"quantificar\"\n",
    "}\n",
    "\n",
    "# Função para download de PDF\n",
    "def download_pdf(url, download_dir):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        filename = os.path.join(download_dir, url.split(\"/\")[-1])\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        return filename\n",
    "    print(f\"Erro ao baixar {url}\")\n",
    "    return None\n",
    "\n",
    "# Função para verificar a presença de verbos-chave\n",
    "def contains_key_verb(sent):\n",
    "    return any(tok.lemma_ in KEY_VERBS for tok in nlp(sent))\n",
    "\n",
    "# Função para determinar a relevância da linha\n",
    "def is_line_irrelevant(line):\n",
    "    lower = line.lower()\n",
    "    if len(lower.strip()) < 15:\n",
    "        return True\n",
    "    if any(k in lower for k in GENERIC_IGNORE_KEYWORDS):\n",
    "        return True\n",
    "    if any(re.search(pattern, lower) for pattern in PHRASE_BLACKLIST):\n",
    "        return True\n",
    "    if re.search(r\"\\d{2}/\\d{2}/\\d{2,4}\", lower):\n",
    "        return True\n",
    "    if lower.endswith(\".pdf\"):\n",
    "        return True\n",
    "    if re.match(r\"^\\d+(\\.\\d+)+\\s+\", lower):\n",
    "        return True\n",
    "    if lower.isupper() and len(lower.split()) > 5:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Função para dividir o texto em blocos menores\n",
    "def split_text(text, max_chars=500000):\n",
    "    chunks = []\n",
    "    while len(text) > max_chars:\n",
    "        split_point = text[:max_chars].rfind(\".\") + 1  # tenta dividir no ponto final\n",
    "        if split_point < 50:\n",
    "            split_point = max_chars  # se não encontrar ponto, quebra direto\n",
    "        chunks.append(text[:split_point].strip())\n",
    "        text = text[split_point:].strip()\n",
    "    if text:\n",
    "        chunks.append(text)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Função para extrair texto relevante\n",
    "def extract_relevant_sentences(text, min_words=4):\n",
    "    relevant = []\n",
    "    chunks = split_text(text)\n",
    "    for chunk in chunks:\n",
    "        doc = nlp(chunk)\n",
    "        for sent in doc.sents:\n",
    "            s = sent.text.strip()\n",
    "            if len(s.split()) < min_words:\n",
    "                continue\n",
    "            if contains_key_verb(s):\n",
    "                relevant.append(s)\n",
    "            elif any(tok.pos_ == \"VERB\" for tok in sent):\n",
    "                relevant.append(s)\n",
    "    return relevant\n",
    "\n",
    "\n",
    "    \n",
    "# Função para extrair texto limpo com spaCy\n",
    "def extract_clean_text_with_spacy(pdf_path, source_url):\n",
    "    try:\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            raw_text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "        lines = raw_text.splitlines()\n",
    "        filtered = [line.strip() for line in lines if not is_line_irrelevant(line.strip())]\n",
    "        cleaned_text = \" \".join(filtered)\n",
    "        relevant_sentences = extract_relevant_sentences(cleaned_text)\n",
    "        return {\n",
    "            \"source_url\": source_url,\n",
    "            \"text\": \"\\n\".join(relevant_sentences) if relevant_sentences else None\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {pdf_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Lista de URLs\n",
    "document_urls = [\n",
    "    \"https://cetesb.sp.gov.br/eiarima/eia/EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf\",\n",
    "    \"https://cetesb.sp.gov.br/eiarima/rima/RIMA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf\",\n",
    "    \"https://www.ibama.gov.br/phocadownload/licenciamento/publicacoes/2020-11-TR_CEM.pdf\",\n",
    "    \"https://www2.senado.leg.br/bdsf/bitstream/handle/id/645769/CF88_EC132_livro.pdf\",\n",
    "    \"https://conama.mma.gov.br/?option=com_sisconama&task=arquivo.download&id=237\",\n",
    "    \"https://www.ibama.gov.br/sophia/cnia/legislacao/IBAMA/IN0184-170708.PDF\",\n",
    "    \"https://cetesb.sp.gov.br/eiarima/eia/EIA-096-24-e-amb-14575-24-Lot-Resid-Jequitiba-Boituva.pdf\",\n",
    "    \"https://cetesb.sp.gov.br/eiarima/rima/RIMA-096-24-e-amb-14575-24-Lot-Resid-Jequitiba-Boituva.pdf\",\n",
    "    \"https://conama.mma.gov.br/?option=com_sisconama&task=arquivo.download&id=745\",\n",
    "    \"https://conama.mma.gov.br/images/conteudo/LivroConama.pdf\",\n",
    "    \n",
    "]\n",
    "\n",
    "# Processamento dos PDFs\n",
    "pdf_texts = {}\n",
    "\n",
    "for url in document_urls:\n",
    "    print(f\"Baixando: {url}...\")\n",
    "    pdf_path = download_pdf(url, download_dir)\n",
    "    if pdf_path:\n",
    "        print(f\"Processando: {pdf_path}...\")\n",
    "        pdf_data = extract_clean_text_with_spacy(pdf_path, url)\n",
    "        if pdf_data:\n",
    "            pdf_texts[os.path.basename(pdf_path)] = pdf_data\n",
    "\n",
    "print(f\"Extração concluída para {len(pdf_texts)} documentos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b24f620-ff48-43bb-914d-af724d217c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto do arquivo EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf dividido em 2880 blocos e embeddings gerados.\n",
      "Texto do arquivo RIMA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf dividido em 166 blocos e embeddings gerados.\n",
      "Texto do arquivo 2020-11-TR_CEM.pdf dividido em 192 blocos e embeddings gerados.\n",
      "Texto do arquivo CF88_EC132_livro.pdf dividido em 3356 blocos e embeddings gerados.\n",
      "Texto do arquivo ?option=com_sisconama&task=arquivo.download&id=237 dividido em 68 blocos e embeddings gerados.\n",
      "Texto do arquivo IN0184-170708.PDF dividido em 64 blocos e embeddings gerados.\n",
      "Texto do arquivo EIA-096-24-e-amb-14575-24-Lot-Resid-Jequitiba-Boituva.pdf dividido em 2641 blocos e embeddings gerados.\n",
      "Texto do arquivo RIMA-096-24-e-amb-14575-24-Lot-Resid-Jequitiba-Boituva.pdf dividido em 17 blocos e embeddings gerados.\n",
      "Texto do arquivo ?option=com_sisconama&task=arquivo.download&id=745 dividido em 32 blocos e embeddings gerados.\n",
      "\n",
      "Os textos de 9 documentos foram particionados e processados em embeddings.\n",
      "Salvando documento: EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf (2880 chunks)\n",
      " -> Documento 'EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf' salvo com sucesso.\n",
      "\n",
      "Salvando documento: RIMA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf (166 chunks)\n",
      " -> Documento 'RIMA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf' salvo com sucesso.\n",
      "\n",
      "Salvando documento: 2020-11-TR_CEM.pdf (192 chunks)\n",
      " -> Documento '2020-11-TR_CEM.pdf' salvo com sucesso.\n",
      "\n",
      "Salvando documento: CF88_EC132_livro.pdf (3356 chunks)\n",
      " -> Documento 'CF88_EC132_livro.pdf' salvo com sucesso.\n",
      "\n",
      "Salvando documento: ?option=com_sisconama&task=arquivo.download&id=237 (68 chunks)\n",
      " -> Documento '?option=com_sisconama&task=arquivo.download&id=237' salvo com sucesso.\n",
      "\n",
      "Salvando documento: IN0184-170708.PDF (64 chunks)\n",
      " -> Documento 'IN0184-170708.PDF' salvo com sucesso.\n",
      "\n",
      "Salvando documento: EIA-096-24-e-amb-14575-24-Lot-Resid-Jequitiba-Boituva.pdf (2641 chunks)\n",
      " -> Documento 'EIA-096-24-e-amb-14575-24-Lot-Resid-Jequitiba-Boituva.pdf' salvo com sucesso.\n",
      "\n",
      "Salvando documento: RIMA-096-24-e-amb-14575-24-Lot-Resid-Jequitiba-Boituva.pdf (17 chunks)\n",
      " -> Documento 'RIMA-096-24-e-amb-14575-24-Lot-Resid-Jequitiba-Boituva.pdf' salvo com sucesso.\n",
      "\n",
      "Salvando documento: ?option=com_sisconama&task=arquivo.download&id=745 (32 chunks)\n",
      " -> Documento '?option=com_sisconama&task=arquivo.download&id=745' salvo com sucesso.\n",
      "\n",
      "\n",
      "9416 chunks armazenados no MongoDB e no ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "# Carregar a chave da API do ambiente\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Função para dividir os textos em chunks\n",
    "def split_text_into_chunks(text, chunk_size=512, chunk_overlap=50):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "    )\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "# Função para gerar os embeddings de cada chunk de acordo com a formatação da OPENAI\n",
    "def generate_embeddings(chunks):\n",
    "    embeddings_model = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "    return embeddings_model.embed_documents(chunks)\n",
    "\n",
    "# Gerando os chunks e embeddings para os textos extraídos dos documentos\n",
    "text_chunks = {}\n",
    "embeddings = {}\n",
    "\n",
    "for pdf_file, pdf_data in pdf_texts.items():\n",
    "    source_url = pdf_data.get(\"source_url\")\n",
    "    full_text = pdf_data.get(\"text\", \"\")\n",
    "\n",
    "    if not isinstance(full_text, str):\n",
    "        print(f\"Aviso: O texto extraído de {pdf_file} não é uma string. Convertendo para string vazia.\")\n",
    "        full_text = \"\"\n",
    "\n",
    "    text_chunks[pdf_file] = split_text_into_chunks(full_text)\n",
    "    embeddings[pdf_file] = generate_embeddings(text_chunks[pdf_file])\n",
    "\n",
    "    print(f\"Texto do arquivo {pdf_file} dividido em {len(text_chunks[pdf_file])} blocos e embeddings gerados.\")\n",
    "\n",
    "print(f\"\\nOs textos de {len(pdf_texts)} documentos foram particionados e processados em embeddings.\")\n",
    "\n",
    "# Salvando dados processados no banco de dados\n",
    "total_chunks = 0\n",
    "\n",
    "for pdf_file in text_chunks:\n",
    "    source_url = pdf_texts[pdf_file].get(\"source_url\")\n",
    "    chunks = text_chunks[pdf_file]\n",
    "    vector_list = embeddings[pdf_file]\n",
    "\n",
    "    print(f\"Salvando documento: {pdf_file} ({len(chunks)} chunks)\")\n",
    "\n",
    "    for idx, (chunk_text, vector) in enumerate(zip(chunks, vector_list)):\n",
    "        chunk_id = f\"{pdf_file}_chunk_{idx}\"\n",
    "\n",
    "        # Verificar se o chunk já existe no MongoDB\n",
    "        if mongo_chunks.find_one({\"chunk_id\": chunk_id}):\n",
    "            print(f\" - Chunk '{chunk_id}' já existe no MongoDB. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        # Verificar se o ID já existe no ChromaDB\n",
    "        existing_ids = collection.get(ids=[chunk_id])\n",
    "        if existing_ids and existing_ids[\"ids\"]:\n",
    "            print(f\" - Chunk '{chunk_id}' já existe no ChromaDB. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        # Inserir no MongoDB\n",
    "        mongo_chunks.insert_one({\n",
    "            \"pdf_file\": pdf_file,\n",
    "            \"chunk_index\": idx,\n",
    "            \"chunk_text\": chunk_text,\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"source_url\": source_url\n",
    "        })\n",
    "        # Inserir no ChromaDB\n",
    "        collection.add(\n",
    "            ids=[chunk_id],\n",
    "            embeddings=[vector],\n",
    "            metadatas=[{\n",
    "                \"chunk_index\": idx,\n",
    "                \"source_file\": pdf_file,\n",
    "                \"source_url\": source_url\n",
    "            }]\n",
    "        )\n",
    "\n",
    "        total_chunks += 1\n",
    "\n",
    "    print(f\" -> Documento '{pdf_file}' salvo com sucesso.\\n\")\n",
    "\n",
    "print(f\"\\n{total_chunks} chunks armazenados no MongoDB e no ChromaDB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87ebffd6-1913-4e49-9a74-4c3f921f31f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultado 1:\n",
      "Documento: EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf\n",
      "Chunk ID: EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf_chunk_915\n",
      "Link: https://cetesb.sp.gov.br/eiarima/eia/EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf\n",
      "Texto: As espécies arbóreas mais frequentes são: açoita-cavalo (Luehea divaricata), canjerana (Cabralea canjerana), chico-pires (Leucochloron incuriale), guaricica (Vochysia magnifica), ingá-mirim (Inga marginata), jacarandá-paulista (Machaerium villosum), joá-de-árvore (Solanum pseudoquina), maria-mole (G...\n",
      "\n",
      "Resultado 2:\n",
      "Documento: EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf\n",
      "Chunk ID: EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf_chunk_959\n",
      "Link: https://cetesb.sp.gov.br/eiarima/eia/EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf\n",
      "Texto: Além dessas também ocorrem: aroeirinha (Schinus terebinthifolia), capororoca (Myrsine umbellata), ingá-mirim (Inga marginata), joá-de-árvore (Solanum pseudoquina), maria-mole (Dendropanax cuneatus), pau-viola (Citharexylum myrianthum), pixirica (Miconia latecrenata), tapiá (Alchornea sidifolia) e uv...\n",
      "\n",
      "Resultado 3:\n",
      "Documento: EIA-096-24-e-amb-14575-24-Lot-Resid-Jequitiba-Boituva.pdf\n",
      "Chunk ID: EIA-096-24-e-amb-14575-24-Lot-Resid-Jequitiba-Boituva.pdf_chunk_732\n",
      "Link: https://cetesb.sp.gov.br/eiarima/eia/EIA-096-24-e-amb-14575-24-Lot-Resid-Jequitiba-Boituva.pdf\n",
      "Texto: Platypodium elegans amendoim-do-campo Melastomataceae Pleroma granulosum Plinia cauliflora\n",
      "Psidium guajava Roystonea oleracea palmeira-imperial\n",
      "Schinus terebinthifolia aroeira-pimenteira CBR 109 Empreendimentos Imobiliários LTDA\n",
      "Tel: + 55 (19)\n",
      "Vernonanthura tweediana Zanthoxylum riedelianum Ressalta...\n",
      "\n",
      "Resultado 4:\n",
      "Documento: EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf\n",
      "Chunk ID: EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf_chunk_894\n",
      "Link: https://cetesb.sp.gov.br/eiarima/eia/EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf\n",
      "Texto: De acordo com os dados apresentados no “Inventário Florestal da Vegetação Natural do Estado de São Paulo” (SIFESP, 2009), o município de São Paulo, com área total de 150.900 ha, possui associada ao maciço da Serra do Mar, destacando-se também o maciço da Cantareira, no limite norte.\n",
      "Já o município d...\n",
      "\n",
      "Resultado 5:\n",
      "Documento: EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf\n",
      "Chunk ID: EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf_chunk_197\n",
      "Link: https://cetesb.sp.gov.br/eiarima/eia/EIA-058-24-e-amb-4841-23-Ampl-CDR-Pedreira-SP-Capital.pdf\n",
      "Texto: Vegetação arbórea ser suprimida\n",
      "................................................................................................................ 39 (CDR PEDREIRA, 2022).............................................................................................................\n",
      "59 Extraído e adaptado...\n"
     ]
    }
   ],
   "source": [
    "#teste de consulta com query\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "def test_query(query: str):\n",
    "    # Gerar o embedding da query\n",
    "    embedding_model = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "    \n",
    "    # Executar a consulta no ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=5\n",
    "    )\n",
    "\n",
    "    # Verificar se houve retorno\n",
    "    if not results[\"metadatas\"]:\n",
    "        print(\"Nenhum resultado encontrado para a query.\")\n",
    "        return\n",
    "\n",
    "    # Exibir os resultados\n",
    "    for idx, metadata in enumerate(results[\"metadatas\"][0]):\n",
    "        chunk_id = metadata[\"source_file\"] + \"_chunk_\" + str(metadata[\"chunk_index\"])\n",
    "        print(f\"\\nResultado {idx + 1}:\")\n",
    "        print(f\"Documento: {metadata['source_file']}\")\n",
    "        print(f\"Chunk ID: {chunk_id}\")\n",
    "        print(f\"Link: {metadata['source_url']}\")\n",
    "        \n",
    "\n",
    "        # Buscar o texto no MongoDB\n",
    "        chunk = mongo_chunks.find_one({\"chunk_id\": chunk_id})\n",
    "        if chunk:\n",
    "            print(f\"Texto: {chunk['chunk_text'][:300]}...\")  # Limitar a exibição a 300 caracteres\n",
    "\n",
    "# Exemplo de consulta\n",
    "test_query(\"quais tipos de árvores exitem em são paulo?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b18a5aa0-e96f-4c12-9d4d-66551944f6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coleção 'chunks' do MongoDB limpa com sucesso.\n"
     ]
    }
   ],
   "source": [
    "#limpar o banco de dadso caso necessário\n",
    "# Conexão com o MongoDB\n",
    "from pymongo import MongoClient\n",
    "\n",
    "mongo_client = MongoClient(\"mongodb://localhost:27017\")\n",
    "mongo_db = mongo_client[\"rag_db\"]\n",
    "mongo_chunks = mongo_db[\"chunks\"]\n",
    "\n",
    "# Remover todos os documentos da collection\n",
    "mongo_chunks.delete_many({})\n",
    "print(\"Coleção 'chunks' do MongoDB limpa com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f48988f-4beb-47c9-b911-755247b0eee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nenhum documento encontrado para remoção no ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "#limpar o chromadb caso necessário\n",
    "import chromadb\n",
    "\n",
    "# Inicializar o cliente ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection = chroma_client.get_or_create_collection(name=\"rag_embeddings\")\n",
    "\n",
    "# Buscar todos os IDs\n",
    "all_ids = collection.get()[\"ids\"]\n",
    "\n",
    "# Remover todos os documentos pelo ID\n",
    "if all_ids:\n",
    "    collection.delete(ids=all_ids)\n",
    "    print(f\"Removidos {len(all_ids)} documentos da coleção 'rag_embeddings'.\")\n",
    "else:\n",
    "    print(\"Nenhum documento encontrado para remoção no ChromaDB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9bc614-7ea0-48f9-bc4f-6b1263023601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
