{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "344fbbe3-0db5-4b0d-bb1c-108550f50e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from pymongo import MongoClient\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from openai import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import MessageGraph\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import Runnable, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d17fcadb-a217-4df3-95b5-354a421d304f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Collection(name=rag_embeddings)]\n"
     ]
    }
   ],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "print(chroma_client.list_collections())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "518175ee-6412-477f-bacc-d15ee664989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Conectar ao MongoDB\n",
    "mongo_client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "mongo_db = mongo_client[\"rag_db\"]\n",
    "mongo_chunks = mongo_db[\"chunks\"]\n",
    "\n",
    "collection = chroma_client.get_collection(\"rag_embeddings\")\n",
    "\n",
    "# Inicializar embeddings\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "729a44b0-e86b-4c4a-966f-7e635665d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict\n",
    "import openai\n",
    "\n",
    "# --- Estado compartilhado ---\n",
    "class ChatState(TypedDict):\n",
    "    input: str\n",
    "    query: str\n",
    "    context: str\n",
    "    answer: str\n",
    "    validation: str\n",
    "\n",
    "# --- Agente de busca no Chroma + MongoDB ---\n",
    "def retrieve_context(state: ChatState) -> ChatState:\n",
    "    query = state[\"input\"]  # <- recebe a entrada inicial do usuário\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding], \n",
    "        n_results=5\n",
    "    )\n",
    "\n",
    "    chunk_ids = []\n",
    "    for result in results[\"metadatas\"][0]:\n",
    "        chunk_ids.append(result[\"source_file\"] + \"_chunk_\" + str(result[\"chunk_index\"]))\n",
    "\n",
    "    chunks_text = []\n",
    "    for chunk_id in chunk_ids:\n",
    "        chunk = mongo_chunks.find_one({\"chunk_id\": chunk_id})\n",
    "        if chunk:\n",
    "            chunks_text.append(chunk[\"chunk_text\"])\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"query\": query,                  # necessário para os próximos nós\n",
    "        \"context\": \"\\n\\n\".join(chunks_text)\n",
    "    }\n",
    "\n",
    "# --- Agente que monta o prompt e chama a OpenAI ---\n",
    "def generate_answer(state: ChatState) -> ChatState:\n",
    "    client = openai.OpenAI(api_key=openai_api_key)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Você é um assistente especialista em licenciamento ambiental, com foco em auxiliar na elaboração de documentos EIA e RIMA. Use exclusivamente o contexto a seguir para responder de forma precisa e técnica.\n",
    "\n",
    "Contexto:\n",
    "{state['context']}\n",
    "\n",
    "Pergunta:\n",
    "{state['query']}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Você é um assistente técnico ambiental especializado em EIA e RIMA.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"answer\": response.choices[0].message.content.strip()\n",
    "    }\n",
    "\n",
    "# --- Agente de validação de resposta ---\n",
    "def AnswerValidatorAgent(state: ChatState) -> ChatState:\n",
    "    client = openai.OpenAI(api_key=openai_api_key)\n",
    "\n",
    "    answer = state[\"answer\"]\n",
    "    context = state[\"context\"]\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    validation_prompt = f\"\"\"\n",
    "Você é um validador técnico. Avalie a resposta de um assistente que tenta responder perguntas sobre EIA e RIMA com base em um contexto técnico.\n",
    "\n",
    "Contexto usado:\n",
    "{context}\n",
    "\n",
    "Pergunta feita:\n",
    "{query}\n",
    "\n",
    "Resposta do assistente:\n",
    "{answer}\n",
    "\n",
    "Agora avalie a resposta com base nos critérios abaixo:\n",
    "1. A resposta está diretamente relacionada ao contexto?\n",
    "2. Há alguma afirmação vaga, genérica ou sem apoio no contexto?\n",
    "3. A linguagem está tecnicamente correta e clara?\n",
    "\n",
    "Se a resposta estiver satisfatória, diga \"VALIDADO\".\n",
    "Se não, explique o problema encontrado.\n",
    "\"\"\"\n",
    "\n",
    "    validation_response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Você é um validador técnico de respostas geradas por IA.\"},\n",
    "            {\"role\": \"user\", \"content\": validation_prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    validation = validation_response.choices[0].message.content.strip()\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"validation\": validation\n",
    "    }\n",
    "\n",
    "# --- Construção do grafo ---\n",
    "builder = StateGraph(ChatState)\n",
    "\n",
    "# Adiciona os nós/etapas\n",
    "builder.add_node(\"retriever\", retrieve_context)\n",
    "builder.add_node(\"chat\", generate_answer)\n",
    "builder.add_node(\"validator\", AnswerValidatorAgent)\n",
    "\n",
    "# Conexões entre os nós\n",
    "builder.set_entry_point(\"retriever\")\n",
    "builder.add_edge(\"retriever\", \"chat\")\n",
    "builder.add_edge(\"chat\", \"validator\")\n",
    "builder.add_edge(\"validator\", END)\n",
    "\n",
    "# Finaliza e compila o grafo\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00fcb5e9-e08a-481d-9a12-302b69ff431d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Você:  Me fale sobre a Lei 14.926/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Desculpe, mas não consigo fornecer informações sobre a Lei 14.926/24, pois essa lei não foi mencionada no contexto fornecido. Além disso, a data de 1924 parece ser muito antiga para as leis ambientais brasileiras modernas. Por favor, verifique a referência da lei e forneça mais detalhes.\n",
      "Validação: A resposta está diretamente relacionada ao contexto e a linguagem está tecnicamente correta e clara. No entanto, há uma afirmação vaga e sem apoio no contexto. O assistente afirma que a data de 1924 parece ser muito antiga para as leis ambientais brasileiras modernas, mas isso não é baseado em nenhuma informação do contexto fornecido. Portanto, a resposta não pode ser totalmente validada.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Você:  mas a lei não é de 1924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: A informação apresentada no contexto não menciona nenhuma lei de 1924. As leis citadas variam de 1965 a 2024. Se você está se referindo a uma lei específica de 1924, por favor, forneça mais detalhes para que eu possa ajudá-lo de maneira mais eficaz.\n",
      "Validação: VALIDADO\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Você:  Lei 14.926/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Desculpe, mas não consigo fornecer informações sobre a Lei 14.926/24, pois ela não foi mencionada no contexto fornecido. Além disso, é importante notar que as leis são específicas para cada país e podem variar significativamente. Portanto, seria útil se você pudesse fornecer mais detalhes ou contexto sobre essa lei específica.\n",
      "Validação: VALIDADO\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Você:  sair\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Você: \")\n",
    "    if user_input.lower() in [\"sair\", \"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    result = graph.invoke({\"input\": user_input})\n",
    "    print(\"Bot:\", result[\"answer\"])\n",
    "    print(\"Validação:\", result[\"validation\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47660f68-56a3-462e-a0d5-08df9164a7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv311)",
   "language": "python",
   "name": "venv311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
