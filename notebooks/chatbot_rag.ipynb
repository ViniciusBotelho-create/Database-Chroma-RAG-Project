{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344fbbe3-0db5-4b0d-bb1c-108550f50e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from pymongo import MongoClient\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from openai import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import MessageGraph\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import Runnable, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17fcadb-a217-4df3-95b5-354a421d304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexão com o ChromaClient Persistente\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518175ee-6412-477f-bacc-d15ee664989f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_139203/571716397.py:12: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings(openai_api_key=openai_api_key) #text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "# Chave da API da openai\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Conectar ao MongoDB\n",
    "mongo_client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "mongo_db = mongo_client[\"rag_db\"]\n",
    "mongo_chunks = mongo_db[\"chunks\"]\n",
    "\n",
    "collection = chroma_client.get_collection(\"rag_embeddings\")\n",
    "\n",
    "# Inicializar embeddings\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=openai_api_key) #text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "729a44b0-e86b-4c4a-966f-7e635665d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Definindo os estados comppartilhados\n",
    "class ChatState(TypedDict):\n",
    "    input: str\n",
    "    query: str\n",
    "    context: str\n",
    "    answer: str\n",
    "    validation: str\n",
    "\n",
    "# Agente de busca\n",
    "def retrieve_context(state: ChatState) -> ChatState:\n",
    "    query = state[\"input\"]  # <- recebe a entrada inicial do usuário\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding], \n",
    "        n_results=5\n",
    "    )\n",
    "\n",
    "    chunk_ids = []\n",
    "    for result in results[\"metadatas\"][0]:\n",
    "        chunk_ids.append(result[\"source_file\"] + \"_chunk_\" + str(result[\"chunk_index\"]))\n",
    "\n",
    "    chunks_text = []\n",
    "    for chunk_id in chunk_ids:\n",
    "        chunk = mongo_chunks.find_one({\"chunk_id\": chunk_id})\n",
    "        if chunk:\n",
    "            chunks_text.append(chunk[\"chunk_text\"])\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"query\": query,                  # necessário para os próximos nós\n",
    "        \"context\": \"\\n\\n\".join(chunks_text)\n",
    "    }\n",
    "\n",
    "# Agente que comunica com a openAI\n",
    "def generate_answer(state: ChatState) -> ChatState:\n",
    "    client = openai.OpenAI(api_key=openai_api_key)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Você é um assistente especialista em licenciamento ambiental, com foco em auxiliar na elaboração de documentos EIA e RIMA. Use exclusivamente o contexto a seguir para responder de forma precisa e técnica.\n",
    "\n",
    "Contexto:\n",
    "{state['context']}\n",
    "\n",
    "Pergunta:\n",
    "{state['query']}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Você é um assistente técnico ambiental especializado em EIA e RIMA.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"answer\": response.choices[0].message.content.strip()\n",
    "    }\n",
    "\n",
    "# Agente que valida a resṕosta obtida\n",
    "def AnswerValidatorAgent(state: ChatState) -> ChatState:\n",
    "    client = openai.OpenAI(api_key=openai_api_key)\n",
    "\n",
    "    answer = state[\"answer\"]\n",
    "    context = state[\"context\"]\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    validation_prompt = f\"\"\"\n",
    "Você é um validador técnico. Avalie a resposta de um assistente que tenta responder perguntas sobre EIA e RIMA com base em um contexto técnico.\n",
    "\n",
    "Contexto usado:\n",
    "{context}\n",
    "\n",
    "Pergunta feita:\n",
    "{query}\n",
    "\n",
    "Resposta do assistente:\n",
    "{answer}\n",
    "\n",
    "Agora avalie a resposta com base nos critérios abaixo:\n",
    "1. A resposta está diretamente relacionada ao contexto?\n",
    "2. Há alguma afirmação vaga, genérica ou sem apoio no contexto?\n",
    "3. A linguagem está tecnicamente correta e clara?\n",
    "\n",
    "Se a resposta estiver satisfatória, diga \"VALIDADO\".\n",
    "Se não, explique o problema encontrado.\n",
    "\"\"\"\n",
    "\n",
    "    validation_response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Você é um validador técnico de respostas geradas por IA.\"},\n",
    "            {\"role\": \"user\", \"content\": validation_prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    validation = validation_response.choices[0].message.content.strip()\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"validation\": validation\n",
    "    }\n",
    "\n",
    "# Construção do grafo\n",
    "builder = StateGraph(ChatState)\n",
    "\n",
    "# Adiciona os nós\n",
    "builder.add_node(\"retriever\", retrieve_context)\n",
    "builder.add_node(\"chat\", generate_answer)\n",
    "builder.add_node(\"validator\", AnswerValidatorAgent)\n",
    "\n",
    "# Conexões entre os nós\n",
    "builder.set_entry_point(\"retriever\")\n",
    "builder.add_edge(\"retriever\", \"chat\")\n",
    "builder.add_edge(\"chat\", \"validator\")\n",
    "builder.add_edge(\"validator\", END)\n",
    "\n",
    "# Finaliza e compila o grafo\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00fcb5e9-e08a-481d-9a12-302b69ff431d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Você:  sair\n"
     ]
    }
   ],
   "source": [
    "#Iteração com o chat\n",
    "while True:\n",
    "    user_input = input(\"Você: \")\n",
    "    if user_input.lower() in [\"sair\", \"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    result = graph.invoke({\"input\": user_input})\n",
    "    print(\"Bot:\", result[\"answer\"])\n",
    "    print(\"Validação:\", result[\"validation\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47660f68-56a3-462e-a0d5-08df9164a7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv311)",
   "language": "python",
   "name": "venv311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
